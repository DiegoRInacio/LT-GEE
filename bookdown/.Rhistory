dbDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
timeZone = "America/Los_Angeles"
###############################################################################################################
###############################################################################################################
###############################################################################################################
siteDirs = normalizePath(list.dirs(dataDir, recursive = F))
tz = timeZone
for(dir in siteDirs){
#dir = siteDirs[2]
print(str_glue('Site: ', dir))
downloadDir = normalizePath(file.path(dir,"downloads"))
archiveDir = normalizePath(file.path(dir,"archive"))
logFiles = normalizePath(list.files(downloadDir, '*', full.names = T))
# if log files then parse it, else next
if(length(logFiles) != 0){
for(logFile in logFiles){
parseScanLog(logFile, tz, dbDir)
# logFile = logFiles[1]
# print(str_glue('    File: ', logFile))
# bname = basename(logFile)
# archiveFile = suppressWarnings(normalizePath(file.path(archiveDir,str_glue(as.character(Sys.Date()),'_',bname))))
#
# lines = read_lines(logFile)
#
#
#
# # is this file orfid or biomark - need to get site name
# lineLen = length(lines)
# end = ifelse(lineLen < 100, lineLen, 100)
# if(length(which(str_detect(lines[1:end], 'Oregon RFID Datalogger') == TRUE)) != 0){
#   site = unlist(str_split(basename(logFile),'_'))[1]
#   reader = 'ORFID'
#   lineStart = substr(lines, 1, 2)
#
#
#   ########## DEAL WITH THE TAG DATA (D CODE)
#   dataMaybe = which(lineStart == 'D ')
#   dataMaybeLength = length(dataMaybe)
#   if(dataMaybeLength > 0){
#     dataLines = spaceDelim(lines[dataMaybe])
#
#     #...do a check on the date to make sure that its a proper date
#     lens = lengths(dataLines)
#     date = unlist(lapply(dataLines, function(l) {unlist(l[2])}))
#     dateCheck = do.call("c", lapply(date, getDate)) # need to use do.call('c') here to unlist because unlist reformats the date
#
#     #... for dates that are good and the number of columns is correct, assume they are tags and put them in a DF
#     tagDataLines = dataMaybe[which(lens == 8 & !is.na(dateCheck))]
#     tagDataLinesLength = length(tagDataLines)
#     if(tagDataLinesLength > 0){
#       tagDataList = spaceDelim(lines[tagDataLines])
#       tagDataMatrix = do.call(rbind, tagDataList)
#       tagDataDF = as.data.frame(tagDataMatrix) %>%  #cbind(tagDataMatrix, tagDataLines)
#         makeORFIDtagDF() %>%
#         addInfo(tagDataLines, archiveFile, site, reader)
#     }
#
#     #... for dates that are good but the number of columns is incorrect, assume they are failed reads and put them in a separate DF
#     tagDataFailLines = dataMaybe[which(lens != 8 & !is.na(dateCheck))]
#     tagDataFailLinesLength = length(tagDataFailLines)
#     if(tagDataFailLinesLength > 0){
#       tagDataFailList = spaceDelim(lines[tagDataFailLines])
#       tagDataFailDF = do.call("rbind", lapply(tagDataFailList, parseORFIDmsg)) %>%
#         addInfo(tagDataFailLines, archiveFile, site, reader)
#     }
#
#     #... for D codes that have a bad date, put them in a separate DF  ---- NEED TO UNMOCK THIS
#     tagDataJunkLines = dataMaybe[which(is.na(dateCheck))]
#     tagDataJunkLinesLength = length(tagDataJunkLines)
#     if(tagDataJunkLinesLength > 0){
#       tagDataJunkVector = lines[tagDataJunkLines] %>%
#         sub("\t", " ", .) %>%
#         str_squish()
#       tagDataJunkDF = data.frame(msg = tagDataJunkVector, stringsAsFactors = F) %>%
#         addInfo(tagDataJunkLines, archiveFile, site, reader)
#     }
#   }
#
#
#   ##########  DEAL WITH THE MESSAGE DATA (E AND B CODES)
#   msgMaybe = which(lineStart == 'E ' | lineStart == 'B ')
#   msgMaybeLength = length(msgMaybe)
#   if(msgMaybeLength > 0){
#     msgLines = spaceDelim(lines[msgMaybe])
#
#     #...do a check on the date to make sure that its a proper date
#     date = unlist(lapply(msgLines, function(l) {unlist(l[2])}))
#     dateCheck = do.call("c", lapply(date, getDate)) # need to use do.call('c') here to unlist because unlist reformats the date
#
#     #... for dates that are good, assume they are messages and put them in a DF
#     msgDataLines = msgMaybe[which(!is.na(dateCheck))]
#     msgDataLinesLength = length(msgDataLines)
#     if(msgDataLinesLength > 0){
#       msgDataList = spaceDelim(lines[msgDataLines])
#       msgDataDF = do.call("rbind", lapply(msgDataList, parseORFIDmsg)) %>%
#         addInfo(msgDataLines, archiveFile, site, reader)
#     }
#
#     #... for E and B codes that have a bad date, put them in a separate DF
#     msgDataJunkLines = msgMaybe[which(is.na(dateCheck))]
#     msgDataJunkLinesLength = length(msgDataJunkLines)
#     if(msgDataJunkLinesLength > 0){
#       msgDataJunkVector = lines[msgDataJunkLines] %>%
#         sub("\t", " ", .) %>%
#         str_squish()
#       msgDataJunkDF = data.frame(msg = msgDataJunkVector, stringsAsFactors = F) %>%
#         addInfo(msgDataJunkLines, archiveFile, site, reader)
#     }
#   }
#
#
#   ##########  DEAL WITH OTHER
#   otherLines = which(lineStart != 'D ' & lineStart != 'E ' & lineStart != 'B ')
#   otherLinesLength = length(otherLines)
#   if(otherLinesLength > 0){
#     otherVector = lines[otherLines] %>%
#       sub("\t", " ", .) %>%
#       str_squish()
#     otherDF = data.frame(msg = otherVector, stringsAsFactors = F) %>%
#       addInfo(otherLines, archiveFile, site, reader)
#   }
#
#
# } else {
#   site = basename(dirname(dirname(logFile)))
#   reader = 'Biomark'
#   lineStart = substr(lines, 1, 4)
#
#   ########## DEAL WITH THE TAG DATA (TAG: CODE)
#   dataMaybe = which(lineStart == 'TAG:')
#   dataMaybeLength = length(dataMaybe)
#   if(dataMaybeLength > 0){
#     dataLines = spaceDelim(lines[dataMaybe])
#
#     #...do a check on the date to make sure that its a proper date
#     lens = lengths(dataLines)
#     date = unlist(lapply(dataLines, function(l) {unlist(l[4])}))
#     dateCheck = do.call("c", lapply(date, getDate)) # need to use do.call('c') here to unlist because unlist reformats the date
#
#     #... for dates that are good and the number of columns is correct, assume they are tags and put them in a DF
#     tagDataLines = dataMaybe[which(lens == 6 & !is.na(dateCheck))]
#     tagDataLinesLength = length(tagDataLines)
#     if(tagDataLinesLength > 0){
#       tagDataList = spaceDelim(lines[tagDataLines])
#       tagDataMatrix = do.call(rbind, tagDataList)
#
#       #tagDataDF = head(as.data.frame(tagDataMatrix))
#       tagDataDF = as.data.frame(tagDataMatrix) %>%  #cbind(tagDataMatrix, tagDataLines)
#         makeBiomarkDF() %>%
#         addInfo(tagDataLines, archiveFile, site, reader)
#     }
#
#     #... for dates that are good but the number of columns is incorrect, assume they are failed reads and put them in a separate DF
#     tagDataFailLines = dataMaybe[which(lens != 6 & !is.na(dateCheck))]
#     tagDataFailLinesLength = length(tagDataFailLines)
#     if(tagDataFailLinesLength > 0){
#       tagDataFailList = spaceDelim(lines[tagDataFailLines])
#       tagDataFailDF = do.call("rbind", lapply(tagDataFailList, parseBiomarkMsg)) %>%
#         addInfo(tagDataFailLines, archiveFile, site, reader)
#     }
#
#     #... for TAG: codes that have a bad date, put them in a separate DF
#     tagDataJunkLines = dataMaybe[which(is.na(dateCheck))]
#     tagDataJunkLinesLength = length(tagDataJunkLines)
#     if(tagDataJunkLinesLength > 0){
#       tagDataJunkVector = lines[tagDataJunkLines] %>%
#         sub("\t", " ", .) %>%
#         str_squish()
#       tagDataJunkDF = data.frame(msg = tagDataJunkVector, stringsAsFactors = F) %>%
#         addInfo(tagDataJunkLines, archiveFile, site, reader)
#     }
#
#
#   }
#
#
#   ##########  DEAL WITH THE MESSAGE DATA (ALM, NRP, SRP AND MSG CODES)
#   msgMaybe = which(lineStart == 'ALM:' | lineStart == 'NRP:' | lineStart == 'SRP:' | lineStart == 'MSG:')
#   msgMaybeLength = length(msgMaybe)
#   if(dataMaybeLength > 0){
#     msgLines = spaceDelim(lines[msgMaybe])
#
#     #...do a check on the date to make sure that its a proper date
#     lens = lengths(msgLines)
#     date = unlist(lapply(msgLines, function(l) {unlist(l[4])}))
#     dateCheck = do.call("c", lapply(date, getDate)) # need to use do.call('c') here to unlist because unlist reformats the date
#
#     #... for dates that are good, assume they are messages and put them in a DF
#     msgDataLines = msgMaybe[which(!is.na(dateCheck))]
#     msgDataLinesLength = length(msgDataLines)
#     if(msgDataLinesLength > 0){
#       msgDataList = spaceDelim(lines[msgDataLines])
#       msgDataDF = do.call("rbind", lapply(msgDataList, parseBiomarkMsg)) %>%
#         addInfo(msgDataLines, archiveFile, site, reader)
#     }
#
#     #... for ALM, NRP, SRP and MSG odes that have a bad date, put them in a separate DF
#     msgDataJunkLines = msgMaybe[which(is.na(dateCheck))]
#     msgDataJunkLinesLength = length(msgDataJunkLines)
#     if(msgDataJunkLinesLength > 0){
#       msgDataJunkVector = lines[msgDataJunkLines] %>%
#         sub("\t", " ", .) %>%
#         str_squish()
#       msgDataJunkDF = data.frame(msg = msgDataJunkVector, stringsAsFactors = F) %>%
#         addInfo(msgDataJunkLines, archiveFile, site, reader)
#     }
#   }
#
#   ##########  DEAL WITH OTHER
#   otherLines = which(lineStart != 'TAG:' | lineStart != 'ALM:' | lineStart != 'NRP:' | lineStart != 'SRP:' | lineStart != 'MSG:')
#   otherLinesLength = length(otherLines)
#   if(otherLinesLength > 0){
#     otherVector = lines[otherLines] %>%
#       sub("\t", " ", .) %>%
#       str_squish()
#     otherDF = data.frame(msg = otherVector, stringsAsFactors = F) %>%
#       addInfo(otherLines, archiveFile, site, reader)
#   }
#
# }
#
# # write out the files here
# # make file names
# tagDataDFfile = file.path(dbDir,'tagDB.csv')
# tagDataFailDFfile = file.path(dbDir,'tagFailDB.csv')
# tagDataJunkDFfile = file.path(dbDir,'tagBadDB.csv')
# msgDataDFfile = file.path(dbDir,'msgDB.csv')
# msgDataJunkDFfile = file.path(dbDir,'msgBadDB.csv')
# otherDFfile = file.path(dbDir,'otherDB.csv')
# logFile = file.path(dbDir,'logDB.csv')
#
# # write them out
# lineLen = length(lines)
# if(exists('tagDataDF')){
#   writeDF(tagDataDF, tagDataDFfile)
#   tagDataDFnrow = nrow(tagDataDF)
#   tagDataDFpercent = round((tagDataDFnrow/lineLen)*100)
# } else {
#   tagDataDFnrow = 0
#   tagDataDFpercent = 0
# }
# print(str_glue('        % tag lines: ', as.character(tagDataDFpercent)))
#
# if(exists('tagDataFailDF')){
#   writeDF(tagDataFailDF, tagDataFailDFfile)
#   tagDataFailDFnrow = nrow(tagDataFailDF)
#   tagDataFailDFpercent = as.character(round((tagDataFailDFnrow/lineLen)*100))
# } else {
#   tagDataFailDFnrow = 0
#   tagDataFailDFpercent = 0
# }
# print(str_glue('        % tag fail lines: ', as.character(tagDataFailDFpercent)))
#
# if(exists('tagDataJunkDF')){
#   writeDF(tagDataJunkDF, tagDataJunkDFfile)
#   tagDataJunkDFnrow = nrow(tagDataJunkDF)
#   tagDataJunkDFpercent = as.character(round((tagDataJunkDFnrow/lineLen)*100))
# } else {
#   tagDataJunkDFnrow = 0
#   tagDataJunkDFpercent = 0
# }
# print(str_glue('        % tag junk lines: ', as.character(tagDataJunkDFpercent)))
#
# if(exists('msgDataDF')){
#   writeDF(msgDataDF, msgDataDFfile)
#   msgDataDFnrow = nrow(msgDataDF)
#   msgDataDFpercent = as.character(round((msgDataDFnrow/lineLen)*100))
# } else {
#   msgDataDFnrow = 0
#   msgDataDFpercent = 0
# }
# print(str_glue('        % message lines: ', as.character(msgDataDFpercent)))
#
# if(exists('msgDataJunkDF')){
#   writeDF(msgDataJunkDF, msgDataJunkDFfile)
#   msgDataJunkDFnrow = nrow(msgDataJunkDF)
#   msgDataJunkDFpercent = as.character(round((msgDataJunkDFnrow/lineLen)*100))
# } else {
#   msgDataJunkDFnrow = 0
#   msgDataJunkDFpercent = 0
# }
# print(str_glue('        % message junk lines: ', as.character(msgDataJunkDFpercent)))
#
# if(exists('otherDF')){
#   writeDF(otherDF, otherDFfile)
#   otherDFnrow = nrow(otherDF)
#   otherDFpercent = as.character(round((otherDFnrow/lineLen)*100))
# } else {
#   otherDFnrow = 0
#   otherDFpercent = 0
# }
# print(str_glue('        % other lines: ', as.character(otherDFpercent)))
#
#
# logDF = data.frame(
#   site=site,
#   reader=reader,
#   fname=archiveFile,
#   dateadded=Sys.Date(),
#   tagpct=tagDataDFpercent,
#   tagfailpct=tagDataFailDFpercent,
#   tagbadpct=tagDataJunkDFpercent,
#   msgpct=msgDataDFpercent,
#   msgbadpct=msgDataJunkDFpercent,
#   otherpct=otherDFpercent,
#   tagnrow=tagDataDFnrow,
#   tagfailnrow=tagDataFailDFnrow,
#   tagbadnrow=tagDataJunkDFnrow,
#   msgnrow=msgDataDFnrow,
#   msgbadnrow=msgDataJunkDFnrow,
#   othernrow=otherDFnrow,
#   totalnrow=lineLen,
#   stringsAsFactors = F
# )
#
# write_csv(logDF, logFile, append=T)
#
# # move the file to the archive
# #file.rename(logFile, archiveFile)
}
} else {
print(str_glue('    No log files for this site'))
next
}
}
#####################################################################################################################
### INPUTS ##########################################################################################################
#####################################################################################################################
functionsPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
dataDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
dbDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
#####################################################################################################################
### INPUTS ##########################################################################################################
#####################################################################################################################
functionsPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
dataDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
dbDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
debugSource('~/GitHub/pit-tag-data-compile/pit_tag_data_compile_functions.r')
PITcompile(dataDir, dbDir, timeZone)
downloadDir
archiveDir
debugSource('~/GitHub/pit-tag-data-compile/pit_tag_data_compile_functions.r')
PITcompile(dataDir, dbDir, timeZone)
tz
functionsPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
dataDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
dbDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
?read_lines
functionsPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
dataDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
dbDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
functionsPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
dataDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
dbDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
functionsPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
dataDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
dbDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
#####################################################################################################################
### INPUTS ##########################################################################################################
#####################################################################################################################
functionsPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
dataDir = "D:\\work\\temp\\tag_test\\ReaderStations"
dbDir = "D:\\work\\temp\\tag_test\\ReaderStations"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
#####################################################################################################################
### INPUTS ##########################################################################################################
#####################################################################################################################
functionsPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
dataDir = "D:\\work\\temp\\tag_test\\ReaderStations"
dbDir = "D:\\work\\temp\\tag_test\\ReaderStations"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
#####################################################################################################################
### INPUTS ##########################################################################################################
#####################################################################################################################
functionsPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
dataDir = "D:\\work\\temp\\tag_test\\ReaderStations"
dbDir = "D:\\work\\temp\\tag_test\\ReaderStations"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
test = try(nchar(dateChunk)==11)
class(test)
class(test) == "try-error"
#####################################################################################################################
### INPUTS ##########################################################################################################
#####################################################################################################################
functionsPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
dataDir = "D:\\work\\temp\\tag_test\\ReaderStations"
dbDir = "D:\\work\\temp\\tag_test\\ReaderStations"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
#####################################################################################################################
### INPUTS ##########################################################################################################
#####################################################################################################################
functionsPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
dataDir = "D:\\work\\temp\\tag_test\\ReaderStations"
dbDir = "D:\\work\\temp\\tag_test\\ReaderStations"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionsPath)
PITcompile(dataDir, dbDir, timeZone)
warnings()
setwd("D:/work/code_library/LT-GEE/bookdown")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
files = list.files('../docs', '.html', full.names = T)
trackingLines = c(
'<!-- Global site tag (gtag.js) - Google Analytics -->',
'<script async src="https://www.googletagmanager.com/gtag/js?id=UA-120674089-1"></script>',
'<script>',
'window.dataLayer = window.dataLayer || [];',
'function gtag(){dataLayer.push(arguments);}',
'gtag(\'js\', new Date());',
'gtag(\'config\', \'UA-120674089-1\');',
'</script>'
)
for(thisFile in files){
lines = readLines(thisFile)
part1 = lines[1:43]
part2 = lines[44:length(lines)]
newLines = c(part1, trackingLines, part2)
writeLines(newLines, thisFile)
}
bookdown::render_book("index.Rmd", "bookdown::gitbook")
files = list.files('../docs', '.html', full.names = T)
trackingLines = c(
'<!-- Global site tag (gtag.js) - Google Analytics -->',
'<script async src="https://www.googletagmanager.com/gtag/js?id=UA-120674089-1"></script>',
'<script>',
'window.dataLayer = window.dataLayer || [];',
'function gtag(){dataLayer.push(arguments);}',
'gtag(\'js\', new Date());',
'gtag(\'config\', \'UA-120674089-1\');',
'</script>'
)
for(thisFile in files){
lines = readLines(thisFile)
part1 = lines[1:43]
part2 = lines[44:length(lines)]
newLines = c(part1, trackingLines, part2)
writeLines(newLines, thisFile)
}
bookdown::render_book("index.Rmd", "bookdown::gitbook")
files = list.files('../docs', '.html', full.names = T)
trackingLines = c(
'<!-- Global site tag (gtag.js) - Google Analytics -->',
'<script async src="https://www.googletagmanager.com/gtag/js?id=UA-120674089-1"></script>',
'<script>',
'window.dataLayer = window.dataLayer || [];',
'function gtag(){dataLayer.push(arguments);}',
'gtag(\'js\', new Date());',
'gtag(\'config\', \'UA-120674089-1\');',
'</script>'
)
for(thisFile in files){
lines = readLines(thisFile)
part1 = lines[1:43]
part2 = lines[44:length(lines)]
newLines = c(part1, trackingLines, part2)
writeLines(newLines, thisFile)
}
bookdown::render_book("index.Rmd", "bookdown::gitbook")
files = list.files('../docs', '.html', full.names = T)
trackingLines = c(
'<!-- Global site tag (gtag.js) - Google Analytics -->',
'<script async src="https://www.googletagmanager.com/gtag/js?id=UA-120674089-1"></script>',
'<script>',
'window.dataLayer = window.dataLayer || [];',
'function gtag(){dataLayer.push(arguments);}',
'gtag(\'js\', new Date());',
'gtag(\'config\', \'UA-120674089-1\');',
'</script>'
)
for(thisFile in files){
lines = readLines(thisFile)
part1 = lines[1:43]
part2 = lines[44:length(lines)]
newLines = c(part1, trackingLines, part2)
writeLines(newLines, thisFile)
}
