line = str_glue(
site,',',
fn,',',
i,',',
line
)
return(line)
}
# give the paths
#fn = "D:\\work\\proj\\pittag\\all_pit_data\\RSC\\Downloads\\RSC_2018_04_06_External_Memory\\01_00089.log" # BioMark
#fn = "D:\\work\\proj\\pittag\\all_pit_data\\Sleepy\\Downloads\\sh1-downstream\\blueTerm_20180315_101235.log" # blueterm, . gap, bad records
#fn = "D:\\work\\proj\\pittag\\all_pit_data\\CAWD\\Downloads\\CAWD_2018_03_12.log" # no indicator and missing ant number
#fn = "D:\\work\\proj\\pittag\\all_pit_data\\CAWD\\Downloads\\CAWD_2017_01_06.TXT" # includes e and d at beginning
# fns = c("D:\\work\\proj\\pittag\\all_pit_data\\RSC\\Downloads\\RSC_2018_04_06_External_Memory\\01_00089.log",
#         "D:\\work\\proj\\pittag\\all_pit_data\\Sleepy\\Downloads\\sh1-downstream\\blueTerm_20180315_101235.log",
#         "D:\\work\\proj\\pittag\\all_pit_data\\CAWD\\Downloads\\CAWD_2018_03_12.log",
#         "D:\\work\\proj\\pittag\\all_pit_data\\CAWD\\Downloads\\CAWD_2017_01_06.TXT")
fileList = read_csv("D:\\work\\proj\\pittag\\all_pit_data\\fileList.csv")
tz = "America/Los_Angeles"
for(f in 1:nrow(fileList)){
fn = fileList$fn[f]
site =fileList$site[f]
position =fileList$position[f]
bname = basename(fn)
# read in the data
lines = read_lines(fn) %>%
str_squish()
# setup the msg dataframe
msgDF = data.frame(
site = '',
date=as.Date('2000-01-01'),
time='00:00:00.00',
fracsec = 0.0,
datetime = strptime('2000-01-01 00:00:00',format='%Y-%m-%d %H:%M:%S', tz=tz),
message = ''
)
# setup the tag dataframe
tagDF = data.frame(
site = '',
position = '',
date = as.Date('2000-01-01'),
time = '00:00:00.00',
fracsec = 0.0,
datetime = strptime('2000-01-01 00:00:00',format='%Y-%m-%d %H:%M:%S', tz=tz),
duration = 0.0,
tagtype = '',
tagid = '',
antnum = '',
consdetc = 0,
arrint = 0,
fname = '',
line = 0
)
# make a bad line holder
badLines = vector()
# loop through the lines
for(i in 1:length(lines)){
# break up the line
print(str_glue(bname,i, .sep = " "))
line = lines[i]
#print(line)
lineChunks = getLineChunks(line)
firstChunk = lineChunks[1]
# figure out what we're dealing with
if(isRecInd(firstChunk)){ # is the first character an 'D' or 'E'
if(firstChunk == 'E'){
df = parseMsg(lineChunks)
df$site = site
msgDF = rbind(msgDF, df)
} else if(firstChunk == 'D'){
df = parseTag(lineChunks)
if(class(df) == 'character'){
#badLine = failedLine(site, fn, i, line)
#badLines = c(badLines, badLine)
next()
}
df$site = site
df$fname = fn
df$line = i
df$position = position
tagDF = rbind(tagDF, df)
}
} else if(!is.na(getDate(firstChunk))){
isMsg = is.na(suppressWarnings(as.numeric(str_sub(lineChunks[3],1,1))))
if(isMsg){
df = parseMsg(lineChunks)
df$site = site
msgDF = rbind(msgDF, df)
} else {
df = parseTag(lineChunks)
if(class(df) == 'character'){
#badLine = failedLine(site, fn, i, line)
#badLines = c(badLines, badLine)
next()
}
df$site = site
df$fname = fn
df$line = i
df$position = position
tagDF = rbind(tagDF, df)
}
} else if(firstChunk == 'MSG:'){
df = parseMTSmsg(lineChunks)
if(class(df) == 'character'){
#badLine = failedLine(site, fn, i, line)
#badLines = c(badLines, badLine)
next()
}
df$site = site
msgDF = rbind(msgDF, df)
} else if(firstChunk == 'TAG:'){
df = parseMTStag(lineChunks)
if(class(df) == 'character'){
#badLine = failedLine(site, fn, i, line)
#badLines = c(badLines, badLine)
next()
}
df$site = site
df$fname = fn
df$line = i
df$position = position
tagDF = rbind(tagDF, df)
}
}
# remove any dup data
tagDF = tagDF[!duplicated(tagDF),]
tagDF = tagDF[2:nrow(tagDF),]
outFile = "D:\\work\\proj\\pittag\\all_pit_data\\tagDB.csv"
write_csv(tagDF, outFile, append=T)
}
lineChunks
f
parseMTSmsg = function(lineChunks){
len = length(lineChunks)
if(len < 6){
return('fail')
}
date = getDate(lineChunks[4])
time = str_sub(lineChunks[5], 1, 11)
fracsec = round(as.numeric(str_sub(time, 9, 11)), 2)
datetime = strptime(paste(date, time),format='%Y-%m-%d %H:%M:%S', tz=tz)
message = str_flatten(lineChunks[6:length(lineChunks)], ' ')
return(data.frame(date, time, fracsec, datetime, message))
}
for(f in 21:nrow(fileList)){
fn = fileList$fn[f]
site =fileList$site[f]
position =fileList$position[f]
bname = basename(fn)
# read in the data
lines = read_lines(fn) %>%
str_squish()
# setup the msg dataframe
msgDF = data.frame(
site = '',
date=as.Date('2000-01-01'),
time='00:00:00.00',
fracsec = 0.0,
datetime = strptime('2000-01-01 00:00:00',format='%Y-%m-%d %H:%M:%S', tz=tz),
message = ''
)
# setup the tag dataframe
tagDF = data.frame(
site = '',
position = '',
date = as.Date('2000-01-01'),
time = '00:00:00.00',
fracsec = 0.0,
datetime = strptime('2000-01-01 00:00:00',format='%Y-%m-%d %H:%M:%S', tz=tz),
duration = 0.0,
tagtype = '',
tagid = '',
antnum = '',
consdetc = 0,
arrint = 0,
fname = '',
line = 0
)
# make a bad line holder
badLines = vector()
# loop through the lines
for(i in 1:length(lines)){
# break up the line
print(str_glue(bname,i, .sep = " "))
line = lines[i]
#print(line)
lineChunks = getLineChunks(line)
firstChunk = lineChunks[1]
# figure out what we're dealing with
if(isRecInd(firstChunk)){ # is the first character an 'D' or 'E'
if(firstChunk == 'E'){
df = parseMsg(lineChunks)
df$site = site
msgDF = rbind(msgDF, df)
} else if(firstChunk == 'D'){
df = parseTag(lineChunks)
if(class(df) == 'character'){
#badLine = failedLine(site, fn, i, line)
#badLines = c(badLines, badLine)
next()
}
df$site = site
df$fname = fn
df$line = i
df$position = position
tagDF = rbind(tagDF, df)
}
} else if(!is.na(getDate(firstChunk))){
isMsg = is.na(suppressWarnings(as.numeric(str_sub(lineChunks[3],1,1))))
if(isMsg){
df = parseMsg(lineChunks)
df$site = site
msgDF = rbind(msgDF, df)
} else {
df = parseTag(lineChunks)
if(class(df) == 'character'){
#badLine = failedLine(site, fn, i, line)
#badLines = c(badLines, badLine)
next()
}
df$site = site
df$fname = fn
df$line = i
df$position = position
tagDF = rbind(tagDF, df)
}
} else if(firstChunk == 'MSG:'){
df = parseMTSmsg(lineChunks)
if(class(df) == 'character'){
#badLine = failedLine(site, fn, i, line)
#badLines = c(badLines, badLine)
next()
}
df$site = site
msgDF = rbind(msgDF, df)
} else if(firstChunk == 'TAG:'){
df = parseMTStag(lineChunks)
if(class(df) == 'character'){
#badLine = failedLine(site, fn, i, line)
#badLines = c(badLines, badLine)
next()
}
df$site = site
df$fname = fn
df$line = i
df$position = position
tagDF = rbind(tagDF, df)
}
}
# remove any dup data
tagDF = tagDF[!duplicated(tagDF),]
tagDF = tagDF[2:nrow(tagDF),]
outFile = "D:\\work\\proj\\pittag\\all_pit_data\\tagDB.csv"
write_csv(tagDF, outFile, append=T)
}
outFile = "D:\\work\\proj\\pittag\\all_pit_data\\tagDB.csv"
df = read_csv(outFile)
df = read_csv(outFile, col_names = F)
nrow(df)
head(df)
which(is.na(df$X3))
naDate = which(is.na(df$X3))
df[naDate,]
df[naDate[4],]
df = df[naDate]
naDate = which(!is.na(df$X3))
df = df[naDate,]
naTime = which(!is.na(df$X4))
df = df[naTime,]
dfo = read_csv(outFile, col_names = F)
nrow(dfo)
nrow(df)
df
naID = which(!is.na(df$X9))
df = df[naID,]
nrow(df)
nafrac = which(!is.na(df$X5))
df = df[nafrac,]
nrow(df)
nadatatime = which(!is.na(df$X6))
df = df[nadatatime,]
nrow(df)
df = df[!duplicated(df),]
nrow(df)
outFile = "D:\\work\\proj\\pittag\\all_pit_data\\tagDBclean.csv"
write_csv(df, outFile)
count(df, x9)
count(df, X9)
unique(df$X9)
as.data.frame(count(df, X9))
inFile = "D:\\work\\proj\\pittag\\all_pit_data\\tagDBclean.csv"
# read in the date
df = read_csv(inFile, col_names = F)
# print the unique tag ids
uniIDs = unique(df$X9)
uniIDs
df
length(uniIDs)
countsPertag = as.data.frame(dplyr::count(df, X9))
countsPertag
# define the data compilation file path
inFile = "D:\\work\\proj\\pittag\\all_pit_data\\tagDB.csv"
# define the cleaned out file to write
outFile = "D:\\work\\proj\\pittag\\all_pit_data\\tagDBclean.csv"
# read in the date
df = read_csv(inFile, col_names = F)
# screen bad rows out
goods = which(!is.na(df$X3))
df = df[goods,]
goods = which(!is.na(df$X4))
df = df[goods,]
goods = which(!is.na(df$X9))
df = df[goods,]
goods = which(!is.na(df$X5))
df = df[goods,]
goods = which(!is.na(df$X6))
df = df[goods,]
# remove any duplicates
df = df[!duplicated(df),]
# write out the clean data compilation
write_csv(df, outFile, col_names = F)
inFile = "D:\\work\\proj\\pittag\\all_pit_data\\tagDBclean.csv"
# read in the date
df = read_csv(inFile, col_names = F)
# print the unique tag ids
uniIDs = unique(df$X9)
print(uniIDs)
#
length(uniIDs)
countsPertag = as.data.frame(dplyr::count(df, X9))
ids
library(tidyverse)
fns = list.files('D:\\work\\proj\\ltee_vs_ltidl\\figures\\ag_profile_examples_data\\', '.csv', full.names=T)
for(i in 1:length(fns)){
if(i == 1){
allDF = read_csv(fns[i])
} else(
allDF = rbind(allDF, read_csv(fns[i]))
)
}
allDF = gather(allDF, "dataType", "NBR", geeData, idlData, srcData)
allDF$dataType = as.factor(allDF$dataType)
levels(allDF$dataType) = c("LT-GEE","LT-IDL","Source")
allDF$dataType <- factor(allDF$dataType, levels = c("LT-GEE","LT-IDL","Source"))
allDF$dataType = factor(allDF$dataType,levels(allDF$dataType)[c(3,2,1)])
ids = unique(allDF$id)
ids
subDF = filter(allDF, id %in% c("region_28_-118946.0_2752922.0", "region_28_-105154.0_2753660.0", "region_28_-112639.0_2748011.0"))
subDF
p = ggplot(subDF, aes(year, NBR, color=dataType)) +
geom_line(size=1.25) +
facet_wrap(~id) +
xlab('Year') +
ylim(c(-0.5,1)) +
labs(color="Data Type") +
scale_color_manual(values=c("#787878", "#619CFF", "#F8766D")) +
theme_bw() +
theme(text = element_text(size = 11),
strip.background = element_blank(),
strip.text.x = element_blank())
p
outName = str_glue('D:\\work\\proj\\ltee_vs_ltidl\\figures\\ag_profile_example_figs\\ag_fit_examples_s789.png')
ggsave(outName, width = 6.5, height = 3, units = "in")
outName = str_glue('D:\\work\\proj\\ltee_vs_ltidl\\figures\\ag_profile_example_figs\\ag_fit_examples_s789.png')
ggsave(outName, width = 6.5, height = 2, units = "in")
outName = str_glue('D:\\work\\proj\\ltee_vs_ltidl\\figures\\ag_profile_example_figs\\ag_fit_examples_s789.png')
ggsave(outName, width = 6.5, height = 1.75, units = "in") # 3 when two rows
outName = str_glue('D:\\work\\proj\\ltee_vs_ltidl\\figures\\ag_profile_example_figs\\ag_fit_examples_s789.png')
ggsave(outName, width = 6.5, height = 1.5, units = "in") # 3 when two rows
library(tidyverse)
# define the data compilation file path
inFile = "D:\\work\\proj\\pittag\\all_pit_data\\tagDB.csv"
# read in the date
df = read_csv(inFile, col_names = F)
# screen bad rows out
goods = which(!is.na(df$X3))
df = df[goods,]
df
this.dir <- dirname(parent.frame(3)$ofile)
parent.frame(3)
parent.frame(3)$ofile
#####################################################################################################################
### INPUTS ##########################################################################################################
#####################################################################################################################
functionPath = "C:\Users\braatenj\Documents\GitHub\pit-tag-data-compile\pit_tag_data_compile_functions.r"
DBfile = "C:\Users\braatenj\Documents\GitHub\pit-tag-data-compile\example\pitTagDB.csv"
inputFileList = "C:\Users\braatenj\Documents\GitHub\pit-tag-data-compile\example\fileList.csv"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionPath)
PITcompile(DBfile, inputFileList, timeZone)
functionPath = "C:\Users\braatenj\Documents\GitHub\pit-tag-data-compile\pit_tag_data_compile_functions.r"
functionPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
DBfile = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\pitTagDB.csv"
inputFileList = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\fileList.csv"
timeZone = "America/Los_Angeles"
source(functionPath)
PITcompile(DBfile, inputFileList, timeZone)
source(functionPath)
PITcompile(DBfile, inputFileList, timeZone)
PITcompile(DBfile, inputFileList, timeZone)
source(functionPath)
functionPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
DBfile = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\pitTagDB.csv"
inputFileList = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\fileList.csv"
timeZone = "America/Los_Angeles"
source(functionPath)
source(functionPath)
PITcompile(DBfile, inputFileList, timeZone)
source(functionPath)
PITcompile(DBfile, inputFileList, timeZone)
today <- Sys.Date()
today
source(functionPath)
PITcompile(DBfile, inputFileList, timeZone)
functionPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
DBfile = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\pitTagDB.csv"
inputFileList = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\fileList1.csv"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionPath)
PITcompile(DBfile, inputFileList, timeZone)
functionPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
DBfile = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\pitTagDB.csv"
inputFileList = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\fileList2.csv"
timeZone = "America/Los_Angeles"
PITcompile(DBfile, inputFileList, timeZone)
library(tidyverse)
DBfile = "D:\\work\\proj\\pittag\\all_pit_data\\tagDBclean.csv"
tagDF = read_csv(DBfile, col_names = F)
?read_csv
vignette("column-types")
cols()
cols(tagDF)
cols(a = "i", b = "d", c = "_")
#####################################################################################################################
### INPUTS ##########################################################################################################
#####################################################################################################################
functionPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
DBfile = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\pitTagDB.csv"
inputFileList = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\fileList1.csv"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionPath)
PITcompile(DBfile, inputFileList, timeZone)
DBfile
tagDF = read_csv(DBfile, col_names = F)
functionPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
DBfile = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\pitTagDB.csv"
inputFileList = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\fileList1.csv"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionPath)
PITcompile(DBfile, inputFileList, timeZone)
functionPath = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\pit_tag_data_compile_functions.r"
DBfile = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\pitTagDB.csv"
inputFileList = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\fileList2.csv"
timeZone = "America/Los_Angeles"
#####################################################################################################################
source(functionPath)
PITcompile(DBfile, inputFileList, timeZone)
install.packages("bookdown")
library('bookdown')
dataDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
normalizePath(dataDir, winslash = "\\")
dataDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example\\"
normalizePath(dataDir, winslash = "\\")
list.dirs(dataDir)
normalizePath(list.dirs(dataDir))
dataDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
normalizePath(list.dirs(dataDir))
?normalizePath
?list.dirs
normalizePath(list.dirs(dataDir, recursive = F))
dataDir = "C:\\Users\\braatenj\\Documents\\GitHub\\pit-tag-data-compile\\example"
siteDirs = normalizePath(list.dirs(dataDir, recursive = F))
for(dir in siteDirs){
print(dir)
}
dir = siteDirs[1]
print(dir)
file.path(dir,"downloads")
?file.path
normalizePath(file.path(dir,"downloads"))
list.files(downloadDir, '*')
downloadDir = normalizePath(file.path(dir,"downloads"))
archiveDir = normalizePath(file.path(dir,"archive"))
# are there files to incorporate
list.files(downloadDir, '*')
list.files(downloadDir, '*', full.names = T)
logFiles = list.files(downloadDir, '*', full.names = T)
length(logFiles)
setwd("D:/work/code_library/LT-GEE/bookdown")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
files = list.files('../docs', '.html', full.names = T)
trackingLines = c(
'<!-- Global site tag (gtag.js) - Google Analytics -->',
'<script async src="https://www.googletagmanager.com/gtag/js?id=UA-120674089-1"></script>',
'<script>',
'window.dataLayer = window.dataLayer || [];',
'function gtag(){dataLayer.push(arguments);}',
'gtag(\'js\', new Date());',
'gtag(\'config\', \'UA-120674089-1\');',
'</script>'
)
for(thisFile in files){
lines = readLines(thisFile)
part1 = lines[1:43]
part2 = lines[44:length(lines)]
newLines = c(part1, trackingLines, part2)
writeLines(newLines, thisFile)
}
